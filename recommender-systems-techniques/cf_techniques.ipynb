{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Filtering Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduce Data Sparsity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To simulate real-world data where users rate only a subset of items, have each user rate a random N selection of programs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ratings = pd.read_csv('../university_user_ratings.csv').set_index('Unnamed: 0')\n",
    "user_ratings.index.names = ['index']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjust sparsity and density of User-Item Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sparse_dataset(df_ratings, sparsity_level):\n",
    "    \"\"\"\n",
    "    Create a sparse dataset by selecting a subset of ratings.\n",
    "\n",
    "    Parameters:\n",
    "    - ratings_df: DataFrame matrix containing the full ratings \n",
    "    - sparsity_level: Percentage of ratings to keep (e.g., 0.1 for 10%)\n",
    "\n",
    "    Returns:\n",
    "    - Sparse ratings DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    ### Calculate number of ratings, each user make (sparsity percent * total university)\n",
    "    rating_per_user = sparsity_level * df_ratings.shape[0]\n",
    "    \n",
    "    sparse_ratings_df = pd.DataFrame().reindex_like(df_ratings)\n",
    "    for user_index in range(df_ratings.shape[1]):\n",
    "        # Each user randomly rate 0.9 - 1.1 of ratings avg\n",
    "        rating_per_user_threshold = random.randint(round(0.9 * rating_per_user), round(1.1 * rating_per_user))\n",
    "        uni_id_to_rate = random.sample(list(range(df_ratings.shape[0])), k=rating_per_user_threshold) \n",
    "        for uni_id in uni_id_to_rate:\n",
    "            sparse_ratings_df.loc[f'uni_id_{uni_id}', f'userid_{user_index}'] \\\n",
    "             = df_ratings.loc[f'uni_id_{uni_id}', f'userid_{user_index}']\n",
    "    return sparse_ratings_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 0.12\n",
      "Density: 0.88\n"
     ]
    }
   ],
   "source": [
    "sparsity_level = float(input(\"Choose sparsity level (0-1): \"))\n",
    "\n",
    "\n",
    "sparse_ratings_df = create_sparse_dataset (user_ratings, sparsity_level)\n",
    "print(f\"Sparsity: {sparsity_level:.2f}\")\n",
    "print(f\"Density: {1-sparsity_level:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjust sparsity and density of User-Item Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Surprise is a Python scikit for building and analyzing recommender systems that deal with explicit rating data.\n",
    "# $ conda install -c conda-forge scikit-surprise\n",
    "from surprise import KNNBasic\n",
    "from surprise import Dataset, Reader\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.prediction_algorithms.matrix_factorization import SVD, NMF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "uni_id     690533\n",
       "user_id    690533\n",
       "ratings    690533\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshape DataFrame\n",
    "melted_df_ratings = sparse_ratings_df.reset_index().melt(id_vars=['index'], var_name='user_id', value_name='ratings')\n",
    "melted_df_ratings.rename(columns={'index': 'uni_id'}, inplace=True)\n",
    "\n",
    "# remove NaN value\n",
    "melted_df_ratings.dropna(inplace=True)\n",
    "\n",
    "reader = Reader() #default is already 1-5\n",
    "dataset = Dataset.load_from_df(melted_df_ratings[['user_id','uni_id','ratings']], reader) #It must have three columns, corresponding to the user (raw) ids, the item (raw) ids, and the ratings, in this order.\n",
    "\n",
    "# melted_df_ratings.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User-based CF using kNN Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "sim_options = {\n",
    "    'name': 'cosine',  # Use cosine similarity\n",
    "    'user_based': True,  # User-based collaborative filtering\n",
    "    'min_support': 3,   # Minimum number of common items for similarity\n",
    "    'shrinkage': 100    # Shrinkage parameter in case of sparse data\n",
    "}\n",
    "\n",
    "# Define the algorithm\n",
    "user_cf = KNNBasic(k=20, min_k=1,sim_options=sim_options,verbose=True)\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "user_cf_cv_results = cross_validate(user_cf, dataset, measures=['RMSE', 'MAE'], cv=3, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Item-based CF using kNN Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Item-Based CF algorithm\n",
    "sim_options = {\n",
    "    'name': 'cosine',  # Use cosine similarity\n",
    "    'user_based': False,  # Item-based collaborative filtering\n",
    "    'min_support': 5,   # Minimum number of common items for similarity\n",
    "    'shrinkage': 100    # Shrinkage parameter in case of sparse data\n",
    "}\n",
    "item_cf = KNNBasic(k=20, min_k=1,sim_options=sim_options, verbose=True)\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "item_cf_cv_results = cross_validate(item_cf, dataset, measures=['RMSE', 'MAE'], cv=3, verbose=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Singular Vector Decomposition (SVD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define SVD algorithm\n",
    "svd_algo = SVD(n_factors=10, n_epochs=20,verbose=True)\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "svd_cv_results = cross_validate(svd_algo, dataset, measures=['RMSE', 'MAE'], cv=3, verbose=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-Negative Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define NMF algorithm\n",
    "nmf_algo = NMF(n_factors=10, n_epochs=20,biased=False)\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "nmf_cv_results = cross_validate(nmf_algo, dataset, measures=['RMSE', 'MAE'], cv=3, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_cv_results(algo_name, cv_results):\n",
    "    mean_rmse = cv_results['test_rmse'].mean()\n",
    "    mean_mae = cv_results['test_mae'].mean()\n",
    "    std_rmse = cv_results['test_rmse'].std()\n",
    "    std_mae = cv_results['test_mae'].std()\n",
    "    print(f\"{algo_name} - RMSE: {mean_rmse:.4f} (± {std_rmse:.4f}), MAE: {mean_mae:.4f} (± {std_mae:.4f})\")\n",
    "\n",
    "print_cv_results(\"User-Based CF\", user_cf_cv_results)\n",
    "print_cv_results(\"Item-Based CF\", item_cf_cv_results)\n",
    "print_cv_results(\"SVD\", svd_cv_results)\n",
    "print_cv_results(\"NMF\", nmf_cv_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
