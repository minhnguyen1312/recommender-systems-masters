{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qZRvJE65_VAl"
   },
   "source": [
    "# Collaborative Filtering Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "MJ_HYwac_VAm"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZmDdW-cH_VAm"
   },
   "source": [
    "## Introduce Data Sparsity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4XPyaQpY_VAn"
   },
   "source": [
    "To simulate real-world data where users rate only a subset of items, have each user rate a random N selection of programs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "PlzJPrTP_VAn"
   },
   "outputs": [],
   "source": [
    "user_ratings = pd.read_csv('../university_user_ratings.csv').set_index('Unnamed: 0')\n",
    "user_ratings.index.names = ['index']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "My_qpavW_VAn"
   },
   "source": [
    "### Adjust sparsity and density of User-Item Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "JQzMHwJJ_VAn"
   },
   "outputs": [],
   "source": [
    "def create_sparse_dataset(df_ratings_matrix, density_level):\n",
    "    \"\"\"\n",
    "    Create a sparse dataset by selecting a subset of ratings.\n",
    "\n",
    "    Parameters:\n",
    "    - ratings_df: DataFrame matrix containing the full ratings\n",
    "    - density_level: Percentage of ratings to keep (e.g., 0.1 for 10%)\n",
    "\n",
    "    Returns:\n",
    "    - Sparse ratings DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    ### Calculate number of ratings, each user make (sparsity percent * total university)\n",
    "    total_ratings = density_level * df_ratings_matrix.size\n",
    "    # rating_per_user = total_ratings / df_ratings_matrix.shape[1]\n",
    "\n",
    "    # Randomly decide the number of ratings per uni_id\n",
    "    uni_id_weights = np.random.dirichlet(alpha=np.ones(df_ratings_matrix.shape[0]))\n",
    "    uni_ratings_distribution = np.random.multinomial(total_ratings, uni_id_weights)\n",
    "\n",
    "    sparse_ratings_df = pd.DataFrame().reindex_like(df_ratings_matrix)\n",
    "    for uni_id, num_ratings_for_uni in enumerate(tqdm(uni_ratings_distribution)):\n",
    "        # Select random users to rate this uni_id\n",
    "        users_to_rate = random.sample(\n",
    "            list(df_ratings_matrix.columns), k=min(num_ratings_for_uni, len(df_ratings_matrix.columns))\n",
    "        )\n",
    "        for user_id in users_to_rate:\n",
    "            # Copy the rating from the original matrix\n",
    "            sparse_ratings_df.loc[f'uni_id_{uni_id}', user_id] = df_ratings_matrix.loc[f'uni_id_{uni_id}', user_id]\n",
    "\n",
    "    return sparse_ratings_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-FbnS0jr_VAn",
    "outputId": "c94a54fb-2d2c-415e-aafc-f5b3525b3c28"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10404/10404 [06:31<00:00, 26.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity: 0.00\n",
      "Density: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sparsity_level = float(input(\"Choose sparsity level (0-1): \"))\n",
    "\n",
    "\n",
    "sparse_ratings_df = create_sparse_dataset (user_ratings, 1-sparsity_level)\n",
    "print(f\"Sparsity: {sparsity_level:.2f}\")\n",
    "print(f\"Density: {1-sparsity_level:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "US1jM5Ax_VAo"
   },
   "source": [
    "## Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "9J9bcRJ9_VAo"
   },
   "outputs": [],
   "source": [
    "# Surprise is a Python scikit for building and analyzing recommender systems that deal with explicit rating data.\n",
    "# $ conda install -c conda-forge scikit-surprise\n",
    "from surprise import Dataset, Reader, KNNBasic, SVD, NMF, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bq-zlHxc_VAo"
   },
   "source": [
    "### Build Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "4XS_f2lVQzFd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average rating per user: 10404.00\n",
      "Average rating per uni: 554.00\n"
     ]
    }
   ],
   "source": [
    "avg_rating_user = np.round((1 - sparsity_level) * user_ratings.shape[0])\n",
    "avg_rating_uni = np.round((1 - sparsity_level) * user_ratings.shape[1])\n",
    "print(f\"Average rating per user: {avg_rating_user:.2f}\")\n",
    "print(f\"Average rating per uni: {avg_rating_uni:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "fLK93ex6_VAo"
   },
   "outputs": [],
   "source": [
    "# reshape DataFrame\n",
    "melted_sparse_ratings = sparse_ratings_df.reset_index().melt(id_vars=['index'], var_name='user_id', value_name='ratings')\n",
    "melted_sparse_ratings.rename(columns={'index': 'uni_id'}, inplace=True)\n",
    "train_df = melted_sparse_ratings.dropna(inplace=False)\n",
    "\n",
    "# reshape DataFrame\n",
    "melted_user_ratings = user_ratings.reset_index().melt(id_vars=['index'], var_name='user_id', value_name='ratings')\n",
    "melted_user_ratings.rename(columns={'index': 'uni_id'}, inplace=True)\n",
    "test_df = melted_user_ratings.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "MjnqA-ddu6gd"
   },
   "outputs": [],
   "source": [
    "reader = Reader() #default is already 1-5\n",
    "\n",
    "sparse_rating_dataset = Dataset.load_from_df(train_df[['user_id', 'uni_id', 'ratings']], reader)\n",
    "trainset = sparse_rating_dataset.build_full_trainset()\n",
    "\n",
    "full_rating_dataset = Dataset.load_from_df(test_df[['user_id', 'uni_id', 'ratings']], reader)\n",
    "testset = full_rating_dataset.build_full_trainset().build_testset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Vd4astFnRinO"
   },
   "outputs": [],
   "source": [
    "# Filter the train_df based on the valid_uni_ids\n",
    "valid_uni_ids = train_df['uni_id'].value_counts()[train_df['uni_id'].value_counts() >= avg_rating_uni].index\n",
    "df = train_df[train_df['uni_id'].isin(valid_uni_ids)]\n",
    "\n",
    "dataset = Dataset.load_from_df(df[['user_id', 'uni_id', 'ratings']], reader)\n",
    "memory_based_train = dataset.build_full_trainset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "x3IfXEj70tDm"
   },
   "outputs": [],
   "source": [
    "# # Define SVD algorithm\n",
    "# svd_algo = SVD(n_factors=15, n_epochs=20,verbose=True)\n",
    "\n",
    "# svd_algo.fit(trainset)\n",
    "# svd_predictions = svd_algo.test(testset)\n",
    "# accuracy.rmse((svd_predictions), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "UHbS8aa90s5-"
   },
   "outputs": [],
   "source": [
    "# # Define NMF algorithm\n",
    "# nmf_algo = NMF(n_factors=15, n_epochs=20,biased=False)\n",
    "\n",
    "# nmf_algo.fit(trainset)\n",
    "# nmf_predictions = nmf_algo.test(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "sr7z9cqGdHjV"
   },
   "outputs": [],
   "source": [
    "# sim_options = {\n",
    "#     'name': 'cosine',  # Use cosine similarity\n",
    "#     'user_based': True,  # User-based collaborative filtering\n",
    "#     'min_support': 5,   # Minimum number of common items for similarity\n",
    "# }\n",
    "\n",
    "# # Define the algorithm\n",
    "# user_cf_algo = KNNBasic(k=20, min_k=1,sim_options=sim_options,verbose=True)\n",
    "\n",
    "# user_cf_algo.fit(memory_based_train)\n",
    "# ub_predictions = user_cf_algo.test(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "b4Mq9djs0qyi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Item-Based CF\n",
      "RMSE: 0.7050\n",
      "MAE:  0.5613\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5613336043936576"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define Item-Based CF algorithm\n",
    "sim_options = {\n",
    "    'name': 'cosine',  # Use cosine similarity\n",
    "    'user_based': False,  # Item-based collaborative filtering\n",
    "    'min_support': 5,   # Minimum number of common items for similarity\n",
    "}\n",
    "item_cf_algo = KNNBasic(k=20, min_k=1,sim_options=sim_options, verbose=True)\n",
    "\n",
    "item_cf_algo.fit(memory_based_train)\n",
    "ib_predictions = item_cf_algo.test(testset)\n",
    "print(\"Item-Based CF\")\n",
    "accuracy.rmse(ib_predictions, verbose=True)\n",
    "accuracy.mae(ib_predictions, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "hn2Y03fB0MmQ"
   },
   "outputs": [],
   "source": [
    "# print(\"User-Based CF\")\n",
    "# accuracy.rmse(ub_predictions, verbose=True)\n",
    "# accuracy.mae(ub_predictions, verbose=True)\n",
    "# print(\"Item-Based CF\")\n",
    "# accuracy.rmse(ib_predictions, verbose=True)\n",
    "# accuracy.mae(ib_predictions, verbose=True)\n",
    "# print(\"SVD\")\n",
    "# accuracy.rmse(svd_predictions, verbose=True)\n",
    "# accuracy.mae(svd_predictions, verbose=True)\n",
    "# print(\"NMF\")\n",
    "# accuracy.rmse(nmf_predictions, verbose=True)\n",
    "# accuracy.mae(nmf_predictions, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "LyQd4KDGfQgm"
   },
   "outputs": [],
   "source": [
    "# from surprise import accuracy, Dataset, SVD\n",
    "# from surprise.model_selection import KFold\n",
    "\n",
    "# sparse_rating_dataset = Dataset.load_from_df(sparse_ratings_df[['user_id', 'uni_id', 'ratings']], reader)\n",
    "# trainset = sparse_rating_dataset.build_full_trainset()\n",
    "\n",
    "# svd_algo = SVD(n_factors=15, n_epochs=20,verbose=False)\n",
    "\n",
    "# full_rating_dataset = Dataset.load_from_df(full_ratings_df[['user_id', 'uni_id', 'ratings']], reader)\n",
    "# testset = full_rating_dataset.build_full_trainset().build_testset()\n",
    "\n",
    "# svd_algo.fit(trainset)\n",
    "# predictions = svd_algo.test(testset)\n",
    "# # # RMSE should be low as we are biased\n",
    "# # accuracy.rmse(predictions, verbose=True)  # ~ 0.68 (which is low)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
